---
layout: post
title: 머신러닝의 분류
excerpt: "머신러닝의 분류 * 지도학습 (Supervised Learning) - 레이블된 훈련데이터를 활용하여 모델을 학습시켜, 본적없는 가까운 미래 데이터에 대해 예측값을 출력하는것, * 비지도학습 (Unsupervised Learning) - 레이블되어있지 않거나 구조를 알 수 없는 데이터를 다루며, 의미 있는 데이터를 추출하여 데이터의 구조를 탐색한다., 강화학습 (Reinforcement learning)"
categories: [인공지능]
comments: true
---

# 머신러닝의 분류

- 지도학습 (Supervised Learning)
    - 레이블된 훈련데이터를 활용하여 모델을 학습시켜, 본적없는 가까운 미래 데이터에 대해 예측값을 출력하는것
        - 분류 (Classification)
            - 과거의 관측 -> 새로운 형태의 범주형 클래스 레이블 예측
        - 회기 (Regression)
            - 데이터가 주어졌을때, 연속적인 출력값을 예측하는 기법
            - 머신러닝 알고리즘은 입력데이터와 출력값이 주어졌을때 두 변수 사이의 관계를 탐색
                - ex) 평수가 넓은 집은 일반적으로 비쌈
- 비지도학습 (Unsupervised Learning)
    - 레이블되어있지 않거나 구조를 알 수 없는 데이터를 다루며, 의미 있는 데이터를 추출하여 데이터의 구조를 탐색한다.
    - 군집
        - 사전정보 없이 쌓여 있는 그룹 정보를 의미 있는 서브그룹 또는 클러스터로 조직하는 탐색석 데이터분석 기법이다. 분석과정에서 만든 클러스터는 어느정도 유사성을 공유하고 정보를 조직화하여 데이터에서 의미있는 관계를 유도하는 훌륭한 도구이다.
        - *K-평균 알고리즘 (K-Means)*
            - 구현이 쉽고, 다른 군집 알고리즘에 비해 계산효율성이 높아 인기가 높다. 보통 학계나 산업현장에서 사용되는 기법이 다르기 마련이지만 이 기법은 모두 널리 사용되고 있다. 
            - 하나의 프로토 타입으로 표현되는 프로토 타입 기반 군집에 속하며 `연속적인 특성`에서는 비슷한 데이터 포인트의 센트로이(Centroid - 평균) `범주형 특성`에서는 메도이드(Medoid - 가장 자주 등장하는 포인트)
            - 원형 클러스터를 구분하는데는 뛰어나지만, KNN(k-nearest neighbors algorithm)알고리즘과 마찬가지로 사전에 몇개의 클러스터를 만들것인지 직접 지정해 줘야 하기때문에 다소 주관적인 사람의 판단이 개입 된다. 적절한 K 값을 선택했다면 높은 성능을 발휘하겠지만, 반대로 적합하지 않는 K 값을 선정했다면 군집 성능을 보장 할 수 없다.
            - 이해를 돕기위한 무작위 데이터 생성 및 시각화 그래프 
             {% highlight python %}
                from sklearn.datasets import make_blobs
                X, y = make_blobs(
                    n_sample = 150,         #150개
                    n_features = 2,         #2차원
                    center = 3,             #3개의 클러스터 중심
                    cluster_std = 0.5,      #클러스터의 표준편차
                    shuffle = True,         #무작위
                    randon_state=0          #시드값 0          
                )
                import matplotlib.pyplot as plt #2차원 산정도를 그려봄
                plt.scatter(X[:,0],
                            X[:,1],
                            c='white',
                            marker='o',
                            edgecolor='black',
                            s=50
                )
                plt.grid()
                plt.tight_layout()
                plt.show()
              {% endhighlight %} 
    
   - K-평 4단계 알고리즘
    
   - 차원축소
        - 고차원의 데이터를 저차원으로 축소하는 기법
        
        
- 강화학습 (Reinforcement learning)
    - 강화 학습(Reinforcement learning)은 기계 학습의 한 영역이다. 행동심리학에서 영감을 받았으며, 어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법이다.
      자전거를 처음 탈때를 기억해 보면 당연히 처음이니 여러번 넘어지고 허벅지도 아프고 많이 힘이 든다. 강화학습 측면에서 이러한 부분은 패털티(penalty)를 받는다고 할 수 있다. 몇 시간이 지나고 나서 이제 넘어지지 않고 잘 달리게 되었다면, 패널티와는 반대로 보상(Reward)을 받는다 라고 할 수 있다.   이렇게 여러번의 시도 거쳐 점점 넘어지지 않는 단계에 이르게 되고 결국 자연스럽게 잘 타게 된다.
      강화 학습은 빠르게 발전을 거듭해 오면서 지금껏 인공지능으로 해결하기 어렵다고 생각한 많은 문제들을 해결해 왔다. 2016년 3월 전세계를 놀라게 한 딥마인드의 알파고와 이세돌9단의 대국은 인공지능의 역사에 있어 한 획을 긋게 된다.
      바둑의 모든 경우의 수를 계산해보면 1161 팩토리얼로 이는 우주전체의 원자 수보다 많은 경우의 수 라고 한다. 또한 바둑은 계산적인 선택 이외에도 간혹 인간의 감각적인 측면에 의해서 승패의 당락이 결정 되어지고는 한다.
    - MDP (Markov decision precess)
        - 강화학습을 한문장으로 정의해 보면 보상을 최대화하는 의사결정전략 즉, 순차적인 행동을 알아 나가는 방법이다. 순차적으로 계속 행동을 결정해하는 문제를 수학적으로 정의한 것
        - 행동, 상태, 보상함수, 상태변환확률, 감가율 로 구성되어 있어있음
         